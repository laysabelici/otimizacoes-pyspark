{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.10",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "## **==================OPÇÕES DE OTIMIZAÇÃO==================**"
            ],
            "metadata": {
                "azdata_cell_guid": "e3f8f792-ade7-4ad7-ad59-38ea89812735"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **EXPLAIN**\n",
                "\n",
                "  \n",
                "\n",
                "##### A função EXPLAIN() é uma ferramenta essencial para inspecionar este plano e pode ajudar a identificar gargalos e oportunidades de otimização."
            ],
            "metadata": {
                "azdata_cell_guid": "1561da32-0706-45bb-bbed-2f28e885b62c"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "##### Ao usar EXPLAIN(), você pode especificar diferentes níveis de detalhe:\r\n",
                "\r\n",
                "1. **`simple`**: Exibe apenas o plano físico.\r\n",
                "2. **`extended`**: Exibe os planos lógico, otimizado e físico.\r\n",
                "3. **`codegen`**: Exibe o código gerado para a execução da consulta.\r\n",
                "4. **`formatted`**: Exibe uma versão detalhada e bem formatada dos planos."
            ],
            "metadata": {
                "azdata_cell_guid": "446c2d75-02d7-4ac2-8983-b0a0f479ab9e"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "#EXEMPLO DE DF\r\n",
                "df = spark.createDataFrame([(1, \"A\"), (2, \"B\"), (3, \"C\")], [\"id\", \"value\"])\r\n",
                "\r\n",
                "#TRANSFORMAÇÃO\r\n",
                "df_filtered = df.filter(df.id > 1)\r\n",
                "\r\n",
                "#EXPLAIN()\r\n",
                "df_filtered.explain()"
            ],
            "metadata": {
                "azdata_cell_guid": "5dfa0fe9-f8b7-4ef0-8b6d-bdfe62b08a53",
                "language": "python",
                "tags": []
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "#EXEMPLO DE DF\r\n",
                "df1 = spark.createDataFrame([(1, \"A\"), (2, \"B\")], [\"id\", \"value\"])\r\n",
                "df2 = spark.createDataFrame([(1, \"X\"), (2, \"Y\")], [\"id\", \"label\"])\r\n",
                "\r\n",
                "#JOIN\r\n",
                "df_joined = df1.join(df2, \"id\")\r\n",
                "df_joined.explain(\"formatted\")\r\n",
                "\r\n",
                "#verifique se o Spark está usando um broadcast join para conjuntos de dados pequenos \r\n",
                "#ou um sort-merge join para conjuntos maiores. \r\n",
                "#Se necessário, force o uso de broadcast joins:\r\n",
                "\r\n",
                "from pyspark.sql.functions import broadcast\r\n",
                "\r\n",
                "df_joined = df1.join(broadcast(df2), \"id\")\r\n",
                "df_joined.explain(\"formatted\")"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "64564f9a-6fb6-417e-9580-9432fdaec3dd",
                "tags": []
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Analisando o Plano de Execução\r\n",
                "\r\n",
                "**Logical Plan:**        \r\n",
                " _Análise de Alto Nível:_ Mostra as operações na forma de uma árvore. Útil para entender a sequência de transformações aplicadas.\r\n",
                " _Otimizações Lógicas:_ Inclui pushdown de filtros, reordenação de joins, etc.\r\n",
                "\r\n",
                "**Optimized Logical Plan:**        \r\n",
                "_Verificação de Otimizações:_ Confirma se otimizações esperadas, como a projeção de colunas, foram aplicadas.\r\n",
                "_Eliminação de Redundâncias:_ Verifica se operações desnecessárias foram removidas.\r\n",
                "\r\n",
                "**Physical Plan:**       \r\n",
                " _Execução Real:_ Mostra como as operações lógicas serão executadas no cluster.\r\n",
                "_Estratégias de Join:_ Identifica o tipo de join (e.g., broadcast, sort-merge).\r\n",
                "_Exchange Operations:_ Mostra onde os dados serão reparticionados ou redistribuídos."
            ],
            "metadata": {
                "azdata_cell_guid": "225d7b83-1577-488e-972b-84d11d9b9203"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "\\======================================================================================="
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "19411d69-0d47-40c5-9022-a8c71a409ec6"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **TÉCNICA OPTIMIZATIONS CATALYTS**\r\n",
                "\r\n",
                "##### O Catalyst é o otimizador de consultas do Spark, responsável por transformar e otimizar o plano de execução das consultas Spark. Ele aplica diversas técnicas para melhorar o desempenho."
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "e21af285-a798-4b66-9180-98fdb556248f"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **Predicate Pushdown (Empurramento de Filtros)**\r\n",
                "##### O Predicate Pushdown refere-se à técnica onde o Catalyst empurra filtros para o nível mais baixo possível do plano de execução. Isso significa que o Spark tenta aplicar filtros o mais cedo possível no processo de leitura dos dados, antes de realizar operações adicionais como joins e agregações. Isso reduz o volume de dados que precisam ser processados, melhorando significativamente o desempenho das consultas.\r\n",
                "\r\n",
                "##### Neste exemplo, o filtro df[\"coluna\"] > 10 é aplicado antes do groupBy, reduzindo o número de linhas que participam na agregação."
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "1eaa36bf-3302-4ff3-8889-b2f9992cb840"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "df.filter(df[\"coluna\"] > 10).groupBy(\"outra_coluna\").count()"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "22f8d0f5-cae9-42de-8c20-3a32b3a58714"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **Column Pruning (Remoção de Colunas)**\r\n",
                "##### A técnica de Column Pruning envolve a remoção de colunas não utilizadas antes da execução da consulta. O Catalyst analisa o plano de execução da consulta e identifica quais colunas são necessárias para satisfazer a operação solicitada. Colunas que não são necessárias para o resultado final da consulta são removidas antes da execução, reduzindo a sobrecarga de leitura e processamento de dados desnecessários.\r\n",
                "\r\n",
                "##### Neste caso, apenas a coluna \"coluna_utilizada\" é mantida após a filtragem, eliminando a necessidade de processar outras colunas do DataFrame."
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "d830929b-f06d-45b6-82ee-db0905848728"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "df.select(\"coluna_utilizada\").filter(df[\"outra_coluna\"] > 20)"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "9b3b71f5-cfc8-46a8-8422-1607bcf2103d"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Funcionamento Interno do Catalyst\r\n",
                "\r\n",
                "O Catalyst opera em três fases principais durante a otimização de consultas:\r\n",
                "\r\n",
                "_Análise (Analysis):_ Durante esta fase, o Catalyst analisa a estrutura da consulta e constrói uma árvore lógica representando a operação solicitada.\r\n",
                "\r\n",
                "_Otimização Lógica (Logical Optimization):_ Nesta fase, o Catalyst aplica transformações na árvore lógica para simplificar e reorganizar as operações, aplicando técnicas como predicate pushdown e column pruning.\r\n",
                "\r\n",
                "_Otimização Física (Physical Optimization):_ Na última fase, o Catalyst converte a árvore lógica otimizada em um plano de execução físico, considerando detalhes como particionamento de dados, métodos de join e estratégias de execução para cada operação."
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "993fc059-8d6c-4a6c-a579-3b6b2b5fb0e9"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "\\======================================================================================="
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "44de9185-e5b9-4b49-947d-43dceecf2d05"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **REDUCE**\n",
                "\n",
                "##### A técnica de usar REDUCE() para unir DataFrames no PySpark é muito útil, mas há situações em que pode não ser a melhor abordagem."
            ],
            "metadata": {
                "azdata_cell_guid": "213b5a36-11ee-442d-adc0-b0462d8331b0"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "#EXEMPLO DE DF\r\n",
                "df1 = spark.createDataFrame([(1, \"A\"), (2, \"B\")], [\"id\", \"value\"])\r\n",
                "df2 = spark.createDataFrame([(3, \"C\"), (4, \"D\")], [\"id\", \"value\"])\r\n",
                "df3 = spark.createDataFrame([(5, \"E\"), (6, \"F\")], [\"id\", \"value\"])\r\n",
                "\r\n",
                "#LISTA DE DF\r\n",
                "dataframes = [df1, df2, df3]\r\n",
                "\r\n",
                "#USO DO REDUCE\r\n",
                "df_final = reduce(DataFrame.unionAll, dataframes)"
            ],
            "metadata": {
                "azdata_cell_guid": "eee735a0-b9f2-465d-bc35-5259c9fab7a9",
                "language": "python",
                "tags": []
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": [
                "##### Evite usar REDUCE para unir DataFrames nos seguintes casos:\n",
                "\n",
                "- Quando os DataFrames têm esquemas diferentes.\n",
                "- Quando o número de DataFrames é muito grande.\n",
                "- Quando há conflitos de particionamento.\n",
                "- Quando a união depende de condições específicas.\n",
                "- Quando são necessárias operações complexas de dados antes ou depois da união."
            ],
            "metadata": {
                "azdata_cell_guid": "e7ae37e6-9d63-447b-b564-6fe92cb29750"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "\\======================================================================================="
            ],
            "metadata": {
                "azdata_cell_guid": "d54f81da-fbde-4029-b495-19b106e38dff"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **BROADCAST**\r\n",
                "\r\n",
                "##### O BROADCAST é uma técnica usada para otimizar operações de join ao distribuir <u>uma pequena tabela</u> (ou DataFrame) para todos os nós do cluster."
            ],
            "metadata": {
                "azdata_cell_guid": "a2613209-a7e1-47b8-8f1a-22f722cf6a78"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Vantagens do broadcast:\r\n",
                "\r\n",
                "_Redução de Movimentação de Dados:_ Como a tabela pequena é enviada para todos os nós, não há necessidade de redistribuir a tabela grande, reduzindo a movimentação de dados pela rede.\r\n",
                "\r\n",
                "_Desempenho Melhorado:_ A realização de joins localmente em cada nó pode acelerar significativamente a operação, especialmente em casos de joins complexos ou grandes volumes de dados.\r\n",
                "\r\n",
                "_Uso Eficiente de Recursos:_ A técnica de broadcast aproveita melhor os recursos do cluster, evitando operações de shuffle custosas."
            ],
            "metadata": {
                "azdata_cell_guid": "6fe3ccec-927b-4dde-a93b-e5983350892f"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "#BIBLIOTECA\r\n",
                "from pyspark.sql.functions import broadcast\r\n",
                "\r\n",
                "# JOIN COM BROADCAST\r\n",
                "df_joined_broadcast = df1.join(broadcast(df2), \"id\")\r\n",
                "\r\n",
                "#PARA VER A DISTRIBUIÇÃO DE TABELAS\r\n",
                "df_joined_broadcast.explain(\"formatted\")"
            ],
            "metadata": {
                "azdata_cell_guid": "e343d9be-df73-4cc7-8bfd-cad5528a5608",
                "language": "python",
                "tags": []
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Quando Usar broadcast:\r\n",
                "\r\n",
                "_Tabela Pequena:_ Use broadcast quando uma das tabelas é relativamente pequena (geralmente cabe na memória de cada nó).\r\n",
                "\r\n",
                "_Join Assimétrico:_ Ideal para joins entre uma tabela grande e uma tabela pequena.\r\n",
                "\r\n",
                "_Desempenho de Join:_ Quando você notar que o desempenho de join é um gargalo devido à movimentação de dados."
            ],
            "metadata": {
                "azdata_cell_guid": "ff8b97eb-f88b-49f5-91dd-3e22e559f29b"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "\\======================================================================================="
            ],
            "metadata": {
                "azdata_cell_guid": "5970f85f-3261-41ec-94b7-37ed081d9522"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **SORT-MERGE**\r\n",
                "\r\n",
                "##### É eficiente para grandes volumes de dados. Spark classifica ambos os DataFrames e os une de maneira ordenada. Esse tipo de join é o padrão no Spark quando ambas as tabelas são grandes."
            ],
            "metadata": {
                "azdata_cell_guid": "72820bf4-1dfd-4bb7-abac-9bfcb46f4203"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "##### Funcionamento do Sort-Merge Join:\r\n",
                "\r\n",
                "**Sorting (Ordenação):**\r\n",
                "Ambos os DataFrames são ordenados pelas colunas de join. Esta etapa garante que os dados relacionados estejam próximos uns dos outros.\r\n",
                "\r\n",
                "**Merging (Mesclagem):**\r\n",
                "Após a ordenação, o Spark realiza uma varredura linear para unir os registros correspondentes das duas tabelas ordenadas."
            ],
            "metadata": {
                "azdata_cell_guid": "56d19a57-1372-4d75-afb7-977e7be9794d"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Vantagens do Sort-Merge Join\r\n",
                "\r\n",
                "_Eficiência para Grandes Dados:_ Sort-merge join é muito eficiente para unir grandes conjuntos de dados porque minimiza a quantidade de dados que precisam ser redistribuídos entre os nós.\r\n",
                "\r\n",
                "_Escalabilidade:_ O sort-merge join pode escalar facilmente com o aumento do tamanho dos dados, pois é projetado para lidar com grandes volumes de dados distribuídos.\r\n",
                "\r\n",
                "_Redução de Movimentação de Dados:_ Ao ordenar os dados antes do join, o sort-merge join garante que os dados relacionados estejam nas mesmas partições, reduzindo significativamente a movimentação de dados pela rede.\r\n",
                "\r\n",
                "_Adequado para Dados Particionados:_ É especialmente útil quando os dados já estão particionados ou podem ser facilmente particionados nas colunas de join.\r\n",
                "\r\n",
                "_Determinismo:_ O processo de sort-merge join é determinístico, o que significa que os resultados são consistentes e previsíveis."
            ],
            "metadata": {
                "azdata_cell_guid": "71c534f2-6220-4462-9c71-f7d15042b773"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# EXEMPLO DF GRANDE\r\n",
                "df1 = spark.range(0, 1e8).toDF(\"id\").withColumn(\"value\", expr(\"id % 1000\"))\r\n",
                "df2 = spark.range(0, 1e8).toDF(\"id\").withColumn(\"label\", expr(\"id % 500\"))\r\n",
                "\r\n",
                "# CONFIGURAÇÃO SORT-MERGE PARA TABELAS GRANDES COM JOIN\r\n",
                "spark.conf.set(\"spark.sql.join.preferSortMergeJoin\", \"true\")\r\n",
                "\r\n",
                "# JOIN\r\n",
                "df_joined = df1.join(df2, \"id\")\r\n",
                "\r\n",
                "#PARA VER A DISTRIBUIÇÃO DE TABELAS\r\n",
                "df_joined.explain(\"formatted\")"
            ],
            "metadata": {
                "azdata_cell_guid": "f614975a-7c50-4d19-b7b4-5892a6aa7ea3",
                "language": "python",
                "tags": []
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Quando Usar Sort-Merge Join\n",
                "\n",
                "_Grandes Conjuntos de Dados:_ Quando ambas as tabelas a serem unidas são grandes e não cabem na memória de cada nó.\n",
                "\n",
                "_Operações de Join Pesadas:_ Quando a operação de join é complexa e envolve muitas linhas em cada tabela.\n",
                "\n",
                "_Dados Particionados ou Ordenados:_ Quando os dados já estão particionados ou podem ser ordenados facilmente nas colunas de join.\n",
                "\n",
                "_Quando Broadcast Não é Viável:_ Quando as tabelas são grandes demais para serem transmitidas (broadcast) eficientemente para todos os nós do cluster."
            ],
            "metadata": {
                "azdata_cell_guid": "5e9d8de5-6530-4d81-b98c-0614a187791d"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "\\======================================================================================="
            ],
            "metadata": {
                "azdata_cell_guid": "702f05f9-8fd4-43dc-94e8-8da0ffe23627"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **SKEW JOIN**\r\n",
                "\r\n",
                "##### Um cenário de dados desbalanceados (ou \"skewed data\") ocorre quando a distribuição dos dados em uma coluna específica não é uniforme, ou seja, alguns valores aparecem com muito mais frequência do que outros. Isso pode levar a um desequilíbrio significativo na carga de trabalho durante operações de join, causando problemas de desempenho.\r\n",
                "\r\n",
                "###### _Categorias de Produtos:_ Em um catálogo de produtos, algumas categorias (como eletrônicos) podem ter muito mais produtos do que outras (como livros)."
            ],
            "metadata": {
                "azdata_cell_guid": "2a4d1543-d91d-4fc1-b671-b87197891c00"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "from pyspark.sql import SparkSession\r\n",
                "\r\n",
                "#EXEMPLO: 100 MB\r\n",
                "spark = SparkSession.builder \\\r\n",
                "    .appName(\"ExemploBroadcastJoin\") \\\r\n",
                "    .config(\"spark.sql.autoBroadcastJoinThreshold\", 100 * 1024 * 1024) \\ \r\n",
                "    .getOrCreate()"
            ],
            "metadata": {
                "azdata_cell_guid": "92d622e3-7d74-42b9-afe3-01ef877aa742",
                "language": "python",
                "tags": []
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "#VALOR ATUAL\r\n",
                "print(\"Valor atual de spark.sql.autoBroadcastJoinThreshold:\",\r\n",
                " spark.conf.get(\"spark.sql.autoBroadcastJoinThreshold\"))"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "9d353fd7-bf9b-4941-ab36-95c5adc17442",
                "tags": []
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Quando Usar Skew Join\r\n",
                "\r\n",
                "Usar técnicas de skew join é recomendado quando você detecta que os dados estão desbalanceados e isso está afetando o desempenho das suas operações de join. As técnicas de skew join ajudam a redistribuir a carga de trabalho de forma mais equilibrada.\r\n",
                "\r\n",
                "O Spark tem uma configuração específica _(spark.sql.autoBroadcastJoinThreshold)_ para ajudar a gerenciar dados desbalanceados automaticamente, mas isso depende do tamanho da tabela."
            ],
            "metadata": {
                "azdata_cell_guid": "fda3c69c-5136-4312-8f4a-e294d3b2f93b"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### **Considerações**\r\n",
                "\r\n",
                "_Tamanho Adequado:_ Escolha um valor apropriado para spark.sql.autoBroadcastJoinThreshold com base na memória disponível nos nós do cluster e no tamanho típico das suas tabelas.\r\n",
                "\r\n",
                "_Monitoramento:_ Monitore o desempenho das suas consultas para ajustar o valor conforme necessário. Um valor muito baixo pode causar muitos broadcast joins, consumindo muita memória, enquanto um valor muito alto pode resultar em shuffles desnecessários."
            ],
            "metadata": {
                "azdata_cell_guid": "3f775703-0f77-4f71-9e74-70f8a32f8fc5"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "\\======================================================================================="
            ],
            "metadata": {
                "azdata_cell_guid": "10570be7-ed81-4dcb-bed5-17ecebe12963"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **PARTITIONBY**"
            ],
            "metadata": {
                "azdata_cell_guid": "70114725-ab68-4ce7-bde8-4295df723a05"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "#FORMATO DELTA E PARTIÇÕES\r\n",
                "spark.read.json('gravação')\\\r\n",
                "    .write.format('delta')\\\r\n",
                "    .partitionBy('COLUNA_ESCOLHIDA') #VERIFIQUE QUE A COLUNA SERÁ MESMO UTILIZADA EM FILTRO\r\n",
                "    .mode('overwrite')\\\r\n",
                "    .saveAsTable('SALVANDO NA TABELA')"
            ],
            "metadata": {
                "azdata_cell_guid": "c20fa1f0-ebf5-4b56-bcb0-6836dcde884a",
                "language": "python",
                "tags": [
                    "hide_input"
                ]
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": [
                "\\======================================================================================="
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "d88b93f7-c7d5-4f30-aa03-fb55099fdc61"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **OPTMIZE e ZORDER BY**\r\n",
                "\r\n",
                "#### São técnicas avançadas de otimização que podem ser aplicadas para melhorar o desempenho de consultas, especialmente em cenários onde a performance é crucial.\r\n",
                "##### COLUNAS PARTICIONADAS NÃO PODEM SER COLOCADAS EM INDICE, DARÁ ERRO.\r\n",
                "\r\n",
                "###### OPTIMIZE refere-se a uma operação específica no contexto do Delta Lake, uma extensão do Apache Spark que oferece funcionalidades adicionais para gerenciar e otimizar data lakes. \r\n",
                "\r\n",
                "###### ZORDER BY escolha colunas que são frequentemente usadas em consultas como critérios de filtro para obter os melhores resultados de desempenho. Como se fossem indices."
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "d74f0f06-6011-45df-9eab-7e089690c831"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "from pyspark.sql.functions import col\r\n",
                "\r\n",
                "df.write\\\r\n",
                "    .format(\"delta\")\\\r\n",
                "    .mode(\"overwrite\")\\\r\n",
                "    .option(\"overwriteSchema\", \"true\")\\\r\n",
                "    .option(\"optimize\", \"true\")\\\r\n",
                "    .option(\"zorderBy\", \"col_name\")\\\r\n",
                "    .save(\"/caminho/para/salvar/tabela\")"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "701e4af8-4a5c-4e40-9e53-06de70bf39d4"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": [
                "\\======================================================================================="
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "411a849e-27fd-4a6d-aa10-0035d6dfddd1"
            },
            "attachments": {}
        }
    ]
}